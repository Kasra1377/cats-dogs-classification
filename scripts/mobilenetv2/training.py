# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQpLlKXfOJFSLcaUX1VlgjK_KvIV06or
"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam , SGD
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report , confusion_matrix
from keras.callbacks import LearningRateScheduler
from sklearn.preprocessing import LabelBinarizer
from tensorflow.keras.utils import to_categorical
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
import math
from imutils import paths
import pandas as pd
import numpy as np
from itertools import chain
import os
import cv2
from PIL import Image
import pickle
import random

plt.style.use("ggplot")

# pickle_in = open("/content/drive/MyDrive/Datasets/PetImages/X-pretrained.pickle" , "rb")
# X = pickle.load(pickle_in)
# pickle_in = open("/content/drive/MyDrive/Datasets/PetImages/y-pretrained.pickle" , "rb")
# y = pickle.load(pickle_in)

# X_preprocessed = []
# y_preprocessed = []
# for img , label in zip(X , y):
#   y_preprocessed.append(label)
#   image = img_to_array(img)
#   image = preprocess_input(image)
#   X_preprocessed.append(image)

path = ["/PetImages/Cat",
         "/PetImages/Dog"]

imagePaths = []
for i in path:
  imagePaths.append(list(paths.list_images(i)))
imagePaths = list(chain.from_iterable(imagePaths))      # converting a 2D list into 1D list

imagePaths[:5]

imagePaths[-5:]

data = []
labels = []
for i in imagePaths:
  try:
    image = load_img(i , target_size = (224 , 224))
    image = img_to_array(image)
    image = preprocess_input(image)
    data.append(image)
    label = i.split(os.path.sep)[-2]
    labels.append(label)
  except Exception as e:
    pass

data = np.array(data , dtype = "float32")
labels = np.array(labels)

# plt.imshow(data[2500])

labels

def plotBarchart(array , figsize = (7 , 7)):
  labels_series = pd.Series(labels)
  ds = labels_series.value_counts().reset_index()      
  ds.columns = ["Name" , "Count"]
  ds["Name"] = ds["Name"].astype("object")

  fig , ax = plt.subplots(figsize = figsize)
  ax = sns.barplot(x = "Name" , y = "Count" , data = ds)
  plt.grid(False)

plotBarchart(labels)

print("X shape : " , data.shape)
print("y shape : " , labels.shape)

X_train , X_test , y_train , y_test = train_test_split(data , labels , test_size = .25 , random_state = 1 , stratify = labels , shuffle = True)

lb = LabelBinarizer()
y_train = lb.fit_transform(y_train)
y_train = to_categorical(y_train)

y_test = lb.fit_transform(y_test)
y_test = to_categorical(y_test)

print("X_train shape : " , X_train.shape)
print("y_train shape : " , y_train.shape)
print("X_test shape : " , X_test.shape)
print("y_test shape : " , y_test.shape)

y_train[44]

label_dict = {0 : "Cat" , 1 : "Dog"}

train_datagen = ImageDataGenerator(
                         rotation_range = 20,
                         zoom_range = 0.15,
                         width_shift_range = 0.2,
                         shear_range = 0.15,
                         horizontal_flip = True,
                         vertical_flip = True, 
                         fill_mode = "nearest"
                        )
# test_datagen = ImageDataGenerator(rescale = 1.0 / 255.0)

baseModel = MobileNetV2(weights = "imagenet" , include_top = False , input_tensor = Input(shape = (224 , 224 , 3)))

baseModel.summary()

headModel = baseModel.output
headModel = AveragePooling2D(pool_size = (7 , 7))(headModel)
headModel = Flatten(name = "Flatten")(headModel)
headModel = Dense(128 , activation = "relu")(headModel)
headModel = Dropout(rate = 0.1)(headModel)
headModel = Dense(2 , activation = "softmax")(headModel)

model = Model(inputs = baseModel.input  , outputs = headModel)

for layer in baseModel.layers:
  layer.trainable = False

model.summary()

class learning_rate_schedule():
  def plot(self, epochs, title="Learning Rate Schedule"):

    lrs = [self(i) for i in epochs]
    plt.figure()
    plt.plot(epochs, lrs)
    plt.title(title)
    plt.xlabel("Epoch #")
    plt.ylabel("Learning Rate")
    plt.show()


class step_decay(learning_rate_schedule):
  def __init__(self, initAlpha = 0.001 , factor = 0.25 , dropEvery = 10):
    self.initAlpha = initAlpha
    self.factor = factor
    self.dropEvery = dropEvery

  def __call__(self, epoch):
    # compute the learning rate for the current epoch
    exp = np.floor((1 + epoch) / self.dropEvery)
    alpha = self.initAlpha * (self.factor ** exp)
    # return the learning rate
    print(alpha)
    return float(alpha)

class polynomial_decay(learning_rate_schedule):
	def __init__(self, maxEpochs=20, initAlpha=0.001, power=1.0):
   
		# store the maximum number of epochs, base learning rate,
		# and power of the polynomial
		self.maxEpochs = maxEpochs
		self.initAlpha = initAlpha
		self.power = power
	def __call__(self, epoch):
		# compute the new learning rate based on polynomial decay
		decay = (1 - (epoch / float(self.maxEpochs))) ** self.power
		alpha = self.initAlpha * decay
		# return the new learning rate
		return float(alpha)

schedule = "step_decay"

if schedule == "linear":
  schedule = polynomial_decay(maxEpochs = 30 , initAlpha = 0.001 , power = 1.0)

if schedule == "polynomial":
  schedule = polynomial_decay(maxEpochs = 30 , initAlpha = 0.001 , power = 3.0)

if schedule == "step_decay":
  schedule = step_decay(initAlpha = 0.001 , factor = 0.25 , dropEvery = 5)

LEARNING_RATE = 0.001
EPOCHS = 10
BS = 24
OPT = Adam(lr = LEARNING_RATE)

lrate = LearningRateScheduler(schedule)
callbacks_list = [lrate]

model.compile(loss = "binary_crossentropy" , optimizer = OPT , metrics = ["accuracy"])

r = model.fit(
    train_datagen.flow(X_train , y_train , batch_size = BS),
    steps_per_epoch = len(X_train) // BS,
    validation_data = (X_test , y_test),
    epochs = EPOCHS
)

N = np.arange(0, EPOCHS)

plt.rcParams["figure.figsize"] = 8 , 6
schedule.plot(N)
plt.show()

# model.save("/models/mobilenetv2-model/cats-dogs-pretrained-model.model")

plt.rcParams["figure.figsize"] = 8 , 6
plt.plot(r.history["loss"] , label = "loss")
plt.plot(r.history["val_loss"] , label = "val_loss")
plt.grid(True)
plt.legend()

plt.rcParams["figure.figsize"] = 8 , 6
plt.plot(r.history["accuracy"] , label = "acc")
plt.plot(r.history["val_accuracy"] , label = "val_acc")
plt.grid(True)
plt.legend()

prediction = model.predict(X_test , batch_size = BS).argmax(axis = 1)

prediction

y_test

print(classification_report(y_test.argmax(axis = 1) , prediction))

label_dict = {0 :"Cat" , 1 : "Dog"}

import itertools
def plot_confusion_matrix(cm , classes , title = "Confusion Matrix" , figsize = (5 ,5) , cmap = plt.cm.Blues):
  
  print(cm)
  
  fig , ax = plt.subplots(figsize = figsize)
  im = ax.imshow(cm ,  interpolation = "nearest" , cmap = cmap)
  ax.set_title(title)
  fig.colorbar(im)
  tick_marks = np.arange(len(classes))
  ax.set_xticks(tick_marks)
  ax.set_yticks(tick_marks)

  thresh = cm.max() / 2
  for i , j in itertools.product(range(cm.shape[0]) , range(cm.shape[1])):
    plt.text(j , i , format(cm[i , j] , "d") , horizontalalignment = "center", 
              color = "white" if cm[i , j] > thresh else "black")
          
  plt.tight_layout()
  plt.ylabel("True Label")
  plt.xlabel("Predicted Label")
  ax.set_xticklabels(label_dict.values())
  ax.set_yticklabels(label_dict.values()) 
  plt.grid(False)
  plt.show()

cm = confusion_matrix(y_test.argmax(axis = 1), prediction)

plot_confusion_matrix(cm , classes = list(range(2)))

y_testFlattened = []
for i in range(len(y_test)):
  y_testFlattened.append(y_test[i][1]) 
y_testFlattened = np.array(y_testFlattened , dtype = "int")

def plotClassified(X_test , predict , y_test , figsize = (15 , 15) , wspace = 0.1  , hspace = 0.3):
  plt.rcParams["axes.grid"] = True
  plt.rcParams["axes.edgecolor"] = "0.15"                 # selecting edge/border color for each image
  plt.rcParams["axes.linewidth"]  = 1.25                  # assining a edge/border width for each image

  fig , axes = plt.subplots(3 , 3 , figsize = figsize)
  plt.subplots_adjust(wspace = wspace , hspace = hspace)        # determining the width gap and height gap between each subplots

  axes = axes.flatten()                                   # for using axes indeces with one dimention array instead of two dimension

  for i in range(0 , 9):
    classified_idx = np.where(predict == y_test)[0]    # representing misclassified images
    n = np.random.choice(classified_idx)
    img = np.reshape(X_test[n], (224 , 224 , 3))                # converting a 1-D array into 2-D 224x224 array
    axes[i].imshow(img , cmap = "gray")
    axes[i].title.set_text("True label : {} , predicted : {}".format(label_dict[y_testFlattened[n]] , label_dict[predict[n]]))
    axes[i].tick_params(labelbottom = False , labelleft = False)    # removing labels/ticks along x axis and y axis
    axes[i].grid(False)

def plotMisclassified(X_test , predict , y_test , figsize = (15 , 15) , wspace = 0.1  , hspace = 0.3):
  
  try:
    plt.rcParams["axes.grid"] = True
    plt.rcParams["axes.edgecolor"] = "0.15"                 # selecting edge/border color for each image
    plt.rcParams["axes.linewidth"]  = 1.25                  # assining a edge/border width for each image

    fig , axes = plt.subplots(3 , 3 , figsize = figsize)
    plt.subplots_adjust(wspace = wspace , hspace = hspace)        # determining the width gap and height gap between each subplots

    axes = axes.flatten()                                   # for using axes indeces with one dimention array instead of two dimension

    for i in range(0 , 9):
      classified_idx = np.where(predict != y_test)[0]    # representing misclassified images
      n = np.random.choice(classified_idx)
      img = np.reshape(X_test[n], (224 , 224 , 3))                # converting a 1-D array into 2-D 224x224 array
      axes[i].imshow(img, cmap = "gray")
      axes[i].title.set_text("True label : {} , predicted : {}".format(label_dict[y_testFlattened[n]] , label_dict[predict[n]]))
      axes[i].tick_params(labelbottom = False , labelleft = False)    # removing labels/ticks along x axis and y axis
      axes[i].grid(False)
  except:
    print("There is nothing to plot here...")

plotClassified(X_test , prediction , y_testFlattened)

plotMisclassified(X_test , prediction , y_testFlattened)